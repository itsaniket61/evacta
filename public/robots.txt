# robots.txt file for your website

# Allow all web crawlers to access all content
User-agent: *
Disallow:

# Disallow specific directories
Disallow: /admin/
Disallow: /login/
Disallow: /register/
Disallow: /settings/

# Disallow specific files
Disallow: /private-file.html

# Allow specific web crawlers to access certain directories
User-agent: Googlebot

# Sitemap location
Sitemap: https://evacta.com/sitemap.xml